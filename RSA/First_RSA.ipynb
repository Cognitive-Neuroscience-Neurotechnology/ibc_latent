{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Notes\n",
    "I want to build an RSA. For this I have several parameters so consider, so I have to do this per subject, contrast (of all tasks), per hemisphere. \n",
    "If there is more than one session of the same space&subject&task&contrast&hemisphere, I guess I should average them?\n",
    "I have the Glasser atlas in fsaverage space (in which I want to work) and the parcels that I want to use (only Frontoparietal) (although those are still in Glasser space I think).\n",
    "I think I need to do per parcel: build a matrix with the shape \"voxels/vertices in parcel\" x \"task_contrasts\". And that per parcel, subject, (hemisphere?).\n",
    "\n",
    "Is taht correct and what are the steps I need to take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "base_dir = '/home/hmueller2/Downloads/contrast_maps/resulting_smooth_maps_surface/' # find the contrast maps here\n",
    "output_dir = '/home/hmueller2/ibc_code/ibc_output_RSA'\n",
    "code_dir = '/home/hmueller2/ibc_code/ibc_latent'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "space = 'fsaverage7' # 'fsaverage5' or 'fsaverage7'\n",
    "\n",
    "subject = '01'\n",
    "session = '00'\n",
    "task = 'ArchiStandard'\n",
    "contrast = 'audio_computation'\n",
    "hemisphere = 'lh' # 'lh' or 'rh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1228653324.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    '''\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# For Pipeline\n",
    "'''\n",
    "def load_surface_maps(file_paths):\n",
    "    data = []\n",
    "    for file_path in file_paths:\n",
    "        img = nib.load(file_path)\n",
    "        data.append(img.get_fdata())\n",
    "    return np.array(data)\n",
    "\n",
    "file_paths = [f\"{base_dir}/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_task-{task}_dir-ffx_space-{space}_hemi-{hemisphere}_ZMap-{contrast}.gii\"]\n",
    "data = load_surface_maps(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.86166986,  0.27651445, -3.55043359, ..., -1.87416169,\n",
       "        -1.80440628, -1.53897857]], shape=(1, 163842))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load gifti and output shape -> amount of vertices / data points (163842)\n",
    "\n",
    "file_path = [f\"{base_dir}/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_task-{task}_dir-ffx_space-{space}_hemi-{hemisphere}_ZMap-{contrast}.gii\"]\n",
    "img = nib.load(file_path[0])\n",
    "data = np.array([darray.data for darray in img.darrays])\n",
    "data.shape\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Representational Similarity Matrix (RSM)\n",
    "def compute_rsm(data):\n",
    "    # Flatten the data to 2D (samples x features)\n",
    "    n_samples, n_vertices, n_timepoints = data.shape\n",
    "    data_reshaped = data.reshape(n_samples, n_vertices * n_timepoints)\n",
    "    # Compute pairwise distances\n",
    "    distances = pdist(data_reshaped, metric='correlation')\n",
    "    # Convert to a square matrix\n",
    "    rsm = squareform(distances)\n",
    "    return rsm\n",
    "\n",
    "# Example subject and task\n",
    "example_data = data[0]  # Assuming data is loaded from the previous step\n",
    "rsm = compute_rsm(example_data)\n",
    "print(rsm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
