{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On my mind (in case I wake up with dementia :D)\n",
    "I want to build an RSA. For this I have several parameters to consider, so I have to do this per subject, contrast (of all tasks), per hemisphere.\n",
    "\n",
    "If there is more than one session of the same task_contrast (space&subject&task&contrast&hemisphere), I guess I should average them?\n",
    "\n",
    "I have the Glasser atlas in fsaverage space (in which I want to work) and the parcels that I want to use (only Frontoparietal). I need to map the voxels from the atlas to all parcels, and then only keep the FPN parcels.\n",
    "\n",
    "With the info on which vertices to include (FPN) I want to shorten the contrast maps from whole brain activation to activation of FPN vertices. Then I will separate those to get beta maps per parcel, per contrast.\n",
    "\n",
    "Question: When looking at parcel X and contrast Y, how do I get from a matrix of *vertices x task* to *task x task* correlation matrix?\n",
    "\n",
    "At this point I am still within a single subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "from nibabel.freesurfer.io import read_annot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "base_dir = 'data/contrast_maps/' # find the contrast maps here\n",
    "output_dir = 'data/output'\n",
    "atlas_dir = 'data/atlas'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load atlas and extract FPN parcels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Glasser: vertex-to-parcel mappings\n",
    "1. **Vertex Labels**: Each vertex on the cortical surface mesh is assigned a label indicating the region or parcel it belongs to (No.: 2 x 163842).\n",
    "2. **Color Table**: A mapping of labels to colors, which helps in visualizing the different regions on the cortical surface.\n",
    "3. **Region Names**: Names of the regions or parcels corresponding to the labels (No.: 2 x 181).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glasser atlas...\n"
     ]
    }
   ],
   "source": [
    "# Load the annotation files\n",
    "lh_annot_file = os.path.join(atlas_dir, 'lh.HCP-MMP1.annot')\n",
    "rh_annot_file = os.path.join(atlas_dir, 'rh.HCP-MMP1.annot')\n",
    "\n",
    "# Read the annotation files\n",
    "labels_lh, ctab_lh, names_lh = read_annot(lh_annot_file)\n",
    "labels_rh, ctab_rh, names_rh = read_annot(rh_annot_file)\n",
    "\n",
    "# Overview on annot (for left hemisphere, but equally applies to right hemisphere)\n",
    "# Labels: Length of labels: 163842 (= amount of vertices in the left hemisphere in fsaverage)\n",
    "print('Length of left hemisphere labels:', len(labels_lh))\n",
    "print('First 15 labels of left hemisphere:', labels_lh[:15])\n",
    "\n",
    "# Parcels: Number of unique labels: 181 (= amount of parcels in the left hemisphere)\n",
    "unique_labels_lh = np.unique(labels_lh)\n",
    "print('Amount of unique labels in left hemisphere:', len(unique_labels_lh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Hemisphere Parcel Mapping (first 5 entries):\n",
      "{np.int64(0): np.bytes_(b'L_6d_ROI'), np.int64(1): np.bytes_(b'L_VIP_ROI'), np.int64(2): np.bytes_(b'L_24dv_ROI'), np.int64(3): np.bytes_(b'L_9-46d_ROI'), np.int64(4): np.bytes_(b'L_43_ROI')}\n",
      "Right Hemisphere Parcel Mapping (first 5 entries):\n",
      "{np.int64(0): np.bytes_(b'R_6mp_ROI'), np.int64(1): np.bytes_(b'R_AIP_ROI'), np.int64(2): np.bytes_(b'R_1_ROI'), np.int64(3): np.bytes_(b'R_46_ROI'), np.int64(4): np.bytes_(b'R_p32pr_ROI')}\n"
     ]
    }
   ],
   "source": [
    "# Create vertex-to-parcel mappings in Glasser atlas\n",
    "vertices_lh = np.arange(len(labels_lh))\n",
    "vertices_rh = np.arange(len(labels_rh))\n",
    "lh_parcel_mapping = {vertex: names_lh[label] for vertex, label in zip(vertices_lh, labels_lh)}\n",
    "rh_parcel_mapping = {vertex: names_rh[label] for vertex, label in zip(vertices_rh, labels_rh)}\n",
    "\n",
    "# Print the first mappings\n",
    "print(\"Left Hemisphere Parcel Mapping (first 5 entries):\")\n",
    "print({k: lh_parcel_mapping[k] for k in list(lh_parcel_mapping)[:5]})\n",
    "\n",
    "print(\"Right Hemisphere Parcel Mapping (first 5 entries):\")\n",
    "print({k: rh_parcel_mapping[k] for k in list(rh_parcel_mapping)[:5]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Network Partition: FPN parcels-vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parcels (= unique labels): 718\n",
      "Number of unique networks (l&r): 12\n",
      "Number of unique glasser labels (l&r): 360\n"
     ]
    }
   ],
   "source": [
    "# Load the text file containing labels of parcels\n",
    "network_partition_path = os.path.join(atlas_dir, 'CortexSubcortex_ColeAnticevic_NetPartition_wSubcorGSR_parcels_LR_LabelKey.txt')\n",
    "network_partition = pd.read_csv(network_partition_path, sep='\\t')\n",
    "\n",
    "# Give out overall amount of parcels\n",
    "print(f\"Total number of parcels (= unique labels): {len(network_partition)}\")\n",
    "print(f\"Number of unique networks (l&r): {network_partition['NETWORK'].nunique()}\")\n",
    "print(f\"Number of unique glasser labels (l&r): {network_partition['GLASSERLABELNAME'].nunique()}\")\n",
    "network_partition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels within FPN: 98\n",
      "Number of unique glasser labels from FPN: 50\n"
     ]
    }
   ],
   "source": [
    "# Extract parcels of FPN\n",
    "fpn_parcels = network_partition[network_partition['NETWORK'] == 'Frontoparietal']\n",
    "\n",
    "# Give out amount of FPN parcels (98, where 46 are in the left hemisphere and 50 in the right hemisphere)\n",
    "print(f\"Number of labels within FPN: {len(fpn_parcels)}\")\n",
    "print(f\"Number of unique glasser labels from FPN: {fpn_parcels['GLASSERLABELNAME'].nunique()}\")\n",
    "fpn_parcels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Glasser parcels from left FPN: 22\n",
      "Number of Glasser parcels from right FPN: 28\n",
      "Number of Glasser parcels from FPN inbetween hemisphere: 0\n"
     ]
    }
   ],
   "source": [
    "# Inspect parcels from left and right hemisphere of FPN separately\n",
    "fpn_parcels_lh = fpn_parcels[fpn_parcels['HEMISPHERE'] == 'L']\n",
    "fpn_parcels_rh = fpn_parcels[fpn_parcels['HEMISPHERE'] == 'R']\n",
    "fpn_parcels_both = fpn_parcels[fpn_parcels['HEMISPHERE'] == 'LR']\n",
    "print(f\"Number of Glasser parcels from left FPN: {fpn_parcels_lh['GLASSERLABELNAME'].nunique()}\")\n",
    "print(f\"Number of Glasser parcels from right FPN: {fpn_parcels_rh['GLASSERLABELNAME'].nunique()}\")\n",
    "print(f\"Number of Glasser parcels from FPN inbetween hemisphere: {fpn_parcels_both['GLASSERLABELNAME'].nunique()}\")\n",
    "fpn_parcels_rh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vertices within parcels of FPN in left hemisphere mapping: 18361\n",
      "Number of vertices within parcels of FPN in right hemisphere mapping: 22966\n",
      "Left Hemisphere Parcel Mapping:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use atlas annotation (lh_parcel_mapping & rh_parcel_mapping) and only keep parcels of FPN\n",
    "# Use GLASSERLABELNAME in fpn_parcels to match with lh_parcel_mapping & rh_parcel_mapping\n",
    "\n",
    "# Left hemisphere: all vertices assigned to parcels of FPN\n",
    "fpn_parcels_lh_names = list(fpn_parcels_lh['GLASSERLABELNAME'].dropna())\n",
    "fpn_parcels_lh_mapping = {vertex: lh_parcel_mapping[vertex] for vertex in vertices_lh if lh_parcel_mapping[vertex].decode('utf-8') in fpn_parcels_lh_names}\n",
    "\n",
    "# Right hemisphere: all vertices assigned to parcels of FPN\n",
    "fpn_parcels_rh_names = list(fpn_parcels_rh['GLASSERLABELNAME'].dropna())\n",
    "fpn_parcels_rh_mapping = {vertex: rh_parcel_mapping[vertex] for vertex in vertices_rh if rh_parcel_mapping[vertex].decode('utf-8') in fpn_parcels_rh_names}\n",
    "\n",
    "# Check if the number of parcels in the mapping is correct\n",
    "print(f\"Number of vertices within parcels of FPN in left hemisphere mapping: {len(fpn_parcels_lh_mapping)}\")\n",
    "print(f\"Number of vertices within parcels of FPN in right hemisphere mapping: {len(fpn_parcels_rh_mapping)}\")\n",
    "\n",
    "# Visualization of vertex - parcel mapping\n",
    "# Convert the mappings to DataFrames for better visualization\n",
    "lh_mapping_df = pd.DataFrame(list(fpn_parcels_lh_mapping.items()), columns=['Vertex', 'Parcel'])\n",
    "rh_mapping_df = pd.DataFrame(list(fpn_parcels_rh_mapping.items()), columns=['Vertex', 'Parcel'])\n",
    "\n",
    "# Display a few entries of the mappings (here left hemisphere)\n",
    "print(\"Left Hemisphere Parcel Mapping:\")\n",
    "lh_mapping_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load contrast data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "space = 'fsaverage7' # 'fsaverage5' or 'fsaverage7'\n",
    "\n",
    "subject = '01'\n",
    "session = '00'\n",
    "task = 'ArchiStandard'\n",
    "contrast = 'audio_computation'\n",
    "hemisphere = 'lh' # 'lh' or 'rh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gifti and output shape -> amount of vertices / data points (163842)\n",
    "\n",
    "file_path = [f\"{base_dir}/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_task-{task}_dir-ffx_space-{space}_hemi-{hemisphere}_ZMap-{contrast}.gii\"]\n",
    "img = nib.load(file_path[0])\n",
    "data = np.array([darray.data for darray in img.darrays])\n",
    "print(f\"Shape of data: {data.shape}\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now turn into pipeline so that you can loop over all subjects, sessions, tasks, contrasts and hemispheres\n",
    "\n",
    "# Needed to come up with RSMs (contrast x contrast)\n",
    "\n",
    "# Initialize lists to store results\n",
    "results = []\n",
    "\n",
    "# Define subjects, sessions, tasks, contrasts, and hemispheres\n",
    "subjects = ['01', '02']  # Add more subjects as needed\n",
    "sessions = ['00', '01']   # Add more sessions as needed\n",
    "tasks = ['ArchiStandard']  # Add more tasks as needed\n",
    "contrasts = ['audio_computation']  # Add more contrasts as needed\n",
    "hemispheres = ['lh', 'rh']  # Left and right hemispheres\n",
    "\n",
    "# Iterate through all combinations\n",
    "for subject in subjects:\n",
    "    for session in sessions:\n",
    "        for task in tasks:\n",
    "            for contrast in contrasts:\n",
    "                for hemisphere in hemispheres:\n",
    "                    # Load data for the current combination\n",
    "                    file_path = [f\"{base_dir}/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_task-{task}_dir-ffx_space-{space}_hemi-{hemisphere}_ZMap-{contrast}.gii\"]\n",
    "                    img = nib.load(file_path[0])\n",
    "                    data = np.array([darray.data for darray in img.darrays])\n",
    "                    # Process data and calculate correlation matrices here\n",
    "                    # Append results to the results list\n",
    "                    results.append((subject, session, task, contrast, hemisphere, data))\n",
    "\n",
    "# Save results to output directory\n",
    "output_file = os.path.join(output_dir, 'results.npy')\n",
    "np.save(output_file, results)\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}